{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import data and set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from utils import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "from easydict import EasyDict as ed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from captum.attr import FeaturePermutation\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "split_by = 'material' # 'random' or 'material'\n",
    "\n",
    "validation = True\n",
    "physics_informed = False\n",
    "bayes_opt = True\n",
    "\n",
    "data_path = '../data/SNL_MSU_DOE_fatigue.xlsx'\n",
    "ckp_path = '../output/fatigue.pt'\n",
    "skopt_path = '../output/skopt.pt'\n",
    "\n",
    "if split_by == 'random':\n",
    "    static_params = {'patience': 500, 'epoch': 2000}\n",
    "    chosen_params = {'lr': 0.0034560325081541875, 'weight_decay': 0.0019904362054363267, 'batch_size': 1024} # for random split\n",
    "    layers = [16, 64, 128, 128, 64, 16]\n",
    "    n_calls = 200\n",
    "    SPACE = [\n",
    "        Real(1e-3, 0.05, 'log-uniform', name='lr'),\n",
    "        Real(1e-5, 0.05, 'log-uniform', name='weight_decay'),\n",
    "        Categorical([32, 64, 128, 256, 512, 1024, 2048, 4096], name='batch_size'),\n",
    "    ]\n",
    "elif split_by == 'material':\n",
    "    static_params = {'patience': 500, 'epoch': 2000}\n",
    "    chosen_params = {'lr': 0.0034560325081541875, 'weight_decay': 0.0019904362054363267, 'batch_size': 1024}\n",
    "    layers = [16, 64, 128, 128, 64, 16]\n",
    "    n_calls = 400\n",
    "    SPACE = [\n",
    "        Real(1e-3, 0.2, 'log-uniform', name='lr'),\n",
    "        Real(1e-8, 0.2, 'log-uniform', name='weight_decay'),\n",
    "        Categorical([32, 64, 128, 256, 512, 1024, 2048, 4096], name='batch_size'),\n",
    "    ]\n",
    "else:\n",
    "    raise Exception('Split not implemented.')\n",
    "\n",
    "if physics_informed:\n",
    "    loss_fn = PI_MSELoss()\n",
    "else:\n",
    "    loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3061 908 839\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(data_path, engine='openpyxl')\n",
    "\n",
    "feature_names = ['Percentage of Fibre in 0-deg Direction',\n",
    "                 'Percentage of Fibre in 45-deg Direction',\n",
    "                 'Percentage of Fibre in 90-deg Direction',\n",
    "                 'Percentage of Fibre in Other Direction',\n",
    "                 'Absolute Maximum Stress',\n",
    "                 'Absolute Peak-to-peak Stress',\n",
    "                 'Frequency',\n",
    "                 'Fibre Volumn Fraction',\n",
    "                 'Relative Maximum Stress',\n",
    "                 'Relative Peak-to-peak Stress',\n",
    "                 'Thickness',\n",
    "                 'Static Maximum Tensile Stress',\n",
    "                 'Static Maximum Tensile Strain',\n",
    "                 'Static Elastic Modulus']\n",
    "\n",
    "label_name = ['Cycles to Failure']\n",
    "\n",
    "feature_data, label_data, X, y, train_dataset, val_dataset, test_dataset, scaler = split_dataset(data, feature_names, label_name, device, validation, split_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gaussian process-based Bayes hyperparameter optimization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adaa2ead00824c35ab33313d18f42292"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if bayes_opt:\n",
    "    bar = tqdm(total=n_calls)\n",
    "\n",
    "    @skopt.utils.use_named_args(SPACE)\n",
    "    def objective(**params):\n",
    "        res = model_train(train_dataset, test_dataset, val_dataset, layers, validation, loss_fn, ckp_path, device,\n",
    "                          verbose=False, return_loss_list=False, **{**params, **static_params})\n",
    "\n",
    "        return res\n",
    "\n",
    "    postfix = {'Current loss': 1e8, 'Minimum': 1e8, 'Params': list(chosen_params.values()), 'Minimum at call': 0}\n",
    "\n",
    "    def callback(result):\n",
    "        postfix['Current loss'] = result.func_vals[-1]\n",
    "\n",
    "        if result.fun < postfix['Minimum']:\n",
    "            postfix['Minimum'] = result.fun\n",
    "            postfix['Params'] = result.x\n",
    "            postfix['Minimum at call'] = len(result.func_vals)\n",
    "        skopt.dump(result, skopt_path)\n",
    "\n",
    "        if len(result.func_vals) % 5 == 0:\n",
    "            plt.figure()\n",
    "            ax = plt.subplot(111)\n",
    "            ax = plot_convergence(result, ax)\n",
    "            plt.savefig('../output/skopt_convergence.svg')\n",
    "            plt.close()\n",
    "\n",
    "        bar.set_postfix(**postfix)\n",
    "        bar.update(1)\n",
    "\n",
    "    result = gp_minimize(objective, SPACE, n_calls=n_calls, random_state=0, x0=list(chosen_params.values()),\n",
    "                         callback=callback)\n",
    "    print(result.func_vals.min())\n",
    "\n",
    "    params = {}\n",
    "    for key,value in zip(chosen_params.keys(), result.x):\n",
    "        params[key] = value\n",
    "\n",
    "    print(params)\n",
    "\n",
    "else:\n",
    "    params = chosen_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = NN(len(feature_names),len(label_name), layers).to(device)\n",
    "\n",
    "min_loss,train_ls,val_ls = model_train(train_dataset, test_dataset, val_dataset, layers, validation, loss_fn, ckp_path, device, model = model, verbose_per_epoch=100, **{**params, **static_params})\n",
    "\n",
    "if validation:\n",
    "    model.load_state_dict(torch.load(ckp_path))\n",
    "else:\n",
    "    torch.save(model.state_dict(), ckp_path)\n",
    "\n",
    "print('Minimum loss:', min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams['font.size'] = 20\n",
    "ax = plt.subplot(111)\n",
    "plot_loss(train_ls, val_ls, ax)\n",
    "plt.savefig('../output/loss_epoch.svg')\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot results and compare NN with baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams['font.size'] = 14\n",
    "ax = plt.subplot(111)\n",
    "plot_truth_pred_NN(train_dataset, val_dataset, test_dataset, model, loss_fn, ax)\n",
    "plt.legend(loc='upper left', markerscale=1.5, handlelength=0.2, handleheight=0.9)\n",
    "\n",
    "plt.savefig('../output/truth_pred.svg')\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams['font.size'] = 14\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "if split_by == 'material':\n",
    "    rf = RandomForestRegressor(n_jobs=-1, max_depth=6)\n",
    "else:\n",
    "    rf = RandomForestRegressor(n_jobs=-1, max_depth=15)\n",
    "\n",
    "plot_truth_pred_sklearn(feature_data, label_data, train_dataset.indices, test_dataset.indices, ax, model = rf, split_by = split_by)\n",
    "plt.legend(loc='upper left', markerscale=1.5, handlelength=0.2, handleheight=0.9)\n",
    "\n",
    "plt.savefig('../output/rf_truth_pred.svg')\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['font.size'] = 14\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "sv = svm.SVR()\n",
    "plot_truth_pred_sklearn(feature_data, label_data, train_dataset.indices, test_dataset.indices, ax, model = sv, split_by = split_by)\n",
    "\n",
    "plt.legend(loc='upper left', markerscale=1.5, handlelength=0.2, handleheight=0.9)\n",
    "\n",
    "plt.savefig('../output/sv_truth_pred.svg')\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def forward_func(data):\n",
    "    prediction, ground_truth, loss = test_tensor(data, y[test_dataset.indices,:], model, loss_fn)\n",
    "    return loss\n",
    "\n",
    "feature_perm = FeaturePermutation(forward_func)\n",
    "attr = feature_perm.attribute(X[test_dataset.indices,:]).cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clr = sns.color_palette(\"deep\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "ax = plt.subplot(111)\n",
    "plot_importance(ax, feature_names, attr, palette = clr)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../output/feature_importance.svg')\n",
    "# plt.close()\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Partial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from utils import calculate_pdp\n",
    "x_values_list = []\n",
    "mean_pdp_list = []\n",
    "\n",
    "\n",
    "for feature_idx in range(len(feature_names)):\n",
    "    print('Calculate PDP: ',feature_names[feature_idx])\n",
    "    \n",
    "    pdp_list = []\n",
    "    ci_left = []\n",
    "    ci_right = []\n",
    "    x_value, model_predictions = calculate_pdp(model,X[train_dataset.indices,:],feature_idx,grid_size=30)\n",
    "    \n",
    "    x_values_list.append(x_value)\n",
    "    mean_pdp_list.append(model_predictions)\n",
    "\n",
    "fig=plot_pdp(feature_names, x_values_list, mean_pdp_list, X, train_dataset.indices)\n",
    "\n",
    "plt.savefig('../output/partial_dependence.svg')\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f15373116f3f1333770e7ecbd767398a2d7ae8734f1a603bc2fc87ae52980838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}